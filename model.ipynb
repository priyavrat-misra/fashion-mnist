{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0e0d1c7ef0f381ce9c31735005e25185fd13b9c57d8e85878ff9ff982cb55e39"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.7.0+cpu\n0.8.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=7*7*16, out_features=128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.layer1(t)\n",
    "        t = self.layer2(t)\n",
    "        t = t.reshape(t.size(0), -1)\n",
    "        t = self.fc1(t)\n",
    "        t = self.fc2(t)\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_set.targets.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.003],\n",
    "    batch_size = [256, 512]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = Network().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle=True, num_workers=1)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    comment = f'-{run}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "    for epoch in range(20):\n",
    "\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        network.train()\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "            preds = network(images)\n",
    "            loss = criterion(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * run.batch_size\n",
    "            train_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Train Loss', train_loss, epoch)\n",
    "        tb.add_scalar('Train Accuracy', train_correct / len(train_set), epoch)\n",
    "        \n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            test_correct = 0\n",
    "            for batch in test_loader:\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "                preds = network(images)\n",
    "                loss = criterion(preds, labels)\n",
    "\n",
    "                test_loss += loss.item() * 256\n",
    "                test_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar('Test Loss', test_loss, epoch)\n",
    "            tb.add_scalar('Test Accuracy', test_correct / len(test_set), epoch)\n",
    "\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "\n",
    "    torch.save(network.state_dict(), f'./models/model-{run}.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "model.load_state_dict(torch.load('models/model-run(lr=0.003, batch_size=256).ckpt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([60000, 10])\ntorch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_loader = torch.utils.data.DataLoader(train_set, batch_size=5000)\n",
    "    train_preds = get_all_preds(model, pred_loader)\n",
    "    test_preds = get_all_preds(model, test_loader)\n",
    "    print(train_preds.shape)\n",
    "    print(test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Correct: 59018\tTrain Accuracy: 98.36%\nTest Correct:   9108\tTest Accuracy:  91.08%\n"
     ]
    }
   ],
   "source": [
    "train_correct = get_num_correct(train_preds, train_set.targets)\n",
    "test_correct = get_num_correct(test_preds, test_set.targets)\n",
    "\n",
    "print('Train Correct: {:5}\\tTrain Accuracy: {:5.2f}%'.format(train_correct, 100*train_correct/len(train_set)))\n",
    "print('Test Correct: {:6}\\tTest Accuracy: {:6.2f}%'.format(test_correct, 100*test_correct/len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stacked = torch.stack(\n",
    "    (train_set.targets, train_preds.argmax(dim=1)),\n",
    "    dim=1\n",
    ")\n",
    "test_stacked = torch.stack(\n",
    "    (test_set.targets, test_preds.argmax(dim=1)),\n",
    "    dim=1\n",
    ")\n",
    "train_confmat = torch.zeros(10, 10, dtype=torch.int16)\n",
    "test_confmat = torch.zeros(10, 10, dtype=torch.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[5764,    0,    7,   33,    1,    1,  194,    0,    0,    0],\n",
       "        [   1, 5989,    0,   10,    0,    0,    0,    0,    0,    0],\n",
       "        [  28,    0, 5866,    4,   50,    0,   52,    0,    0,    0],\n",
       "        [   8,    0,    4, 5966,   11,    0,   11,    0,    0,    0],\n",
       "        [   3,    0,  127,   32, 5803,    0,   35,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0, 5994,    0,    5,    0,    1],\n",
       "        [ 110,    0,   93,   18,   57,    0, 5721,    0,    1,    0],\n",
       "        [   0,    0,    0,    0,    0,   11,    0, 5985,    0,    4],\n",
       "        [   1,    0,    1,    0,    1,    0,    0,    0, 5997,    0],\n",
       "        [   0,    0,    0,    0,    0,    5,    0,   62,    0, 5933]],\n",
       "       dtype=torch.int16)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "print(train_set.classes)\n",
    "for row in train_stacked:\n",
    "    cl, pl = row.tolist()\n",
    "    train_confmat[cl, pl] += 1\n",
    "\n",
    "train_confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[841,   0,  12,  15,   3,   0, 124,   0,   5,   0],\n",
       "        [  1, 978,   0,  14,   1,   0,   3,   0,   3,   0],\n",
       "        [ 21,   1, 863,   9,  47,   0,  59,   0,   0,   0],\n",
       "        [ 13,   2,   8, 928,  22,   0,  27,   0,   0,   0],\n",
       "        [  2,   0,  65,  26, 845,   0,  61,   0,   1,   0],\n",
       "        [  0,   0,   0,   0,   0, 987,   0,  10,   0,   3],\n",
       "        [ 90,   0,  65,  26,  67,   0, 747,   0,   5,   0],\n",
       "        [  0,   0,   0,   0,   0,   6,   0, 982,   1,  11],\n",
       "        [  2,   1,   2,   3,   3,   2,   3,   2, 982,   0],\n",
       "        [  1,   0,   0,   0,   1,   4,   0,  39,   0, 955]], dtype=torch.int16)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "print(test_set.classes)\n",
    "for row in test_stacked:\n",
    "    cl, pl = row.tolist()\n",
    "    test_confmat[cl, pl] += 1\n",
    "\n",
    "test_confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy of T-shirt/top :\t96.07% (5764/6000)\nTrain accuracy of Trouser     :\t99.82% (5989/6000)\nTrain accuracy of Pullover    :\t97.77% (5866/6000)\nTrain accuracy of Dress       :\t99.43% (5966/6000)\nTrain accuracy of Coat        :\t96.72% (5803/6000)\nTrain accuracy of Sandal      :\t99.90% (5994/6000)\nTrain accuracy of Shirt       :\t95.35% (5721/6000)\nTrain accuracy of Sneaker     :\t99.75% (5985/6000)\nTrain accuracy of Bag         :\t99.95% (5997/6000)\nTrain accuracy of Ankle boot  :\t98.88% (5933/6000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Train accuracy of {:12s}:\\t{:.2f}% ({}/{})'.format(\n",
    "        train_set.classes[i],\n",
    "        train_confmat[i, i]/60,\n",
    "        train_confmat[i, i],\n",
    "        6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test accuracy of T-shirt/top :\t84.10% (841/1000)\nTest accuracy of Trouser     :\t97.80% (978/1000)\nTest accuracy of Pullover    :\t86.30% (863/1000)\nTest accuracy of Dress       :\t92.80% (928/1000)\nTest accuracy of Coat        :\t84.50% (845/1000)\nTest accuracy of Sandal      :\t98.70% (987/1000)\nTest accuracy of Shirt       :\t74.70% (747/1000)\nTest accuracy of Sneaker     :\t98.20% (982/1000)\nTest accuracy of Bag         :\t98.20% (982/1000)\nTest accuracy of Ankle boot  :\t95.50% (955/1000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Test accuracy of {:12s}:\\t{:.2f}% ({}/{})'.format(\n",
    "        train_set.classes[i],\n",
    "        test_confmat[i, i]/10,\n",
    "        test_confmat[i, i],\n",
    "        1000))"
   ]
  }
 ]
}