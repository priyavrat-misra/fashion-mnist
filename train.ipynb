{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0e0d1c7ef0f381ce9c31735005e25185fd13b9c57d8e85878ff9ff982cb55e39"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import device, get_num_correct, RunBuilder\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# extract and transform the data\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# load the test set\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hyper-parameter search\n",
    "from collections import OrderedDict\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.003],\n",
    "    batch_size = [256, 512]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # specify loss function (categorical cross-entropy)\n",
    "\n",
    "# iterate through the cross product of hyper-parameters defined in params\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = Network().to(device)  # initialize the NN\n",
    "    # load the train set\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle=True, num_workers=1)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)  # sprecify the optimizer\n",
    "\n",
    "    comment = f'-{run}'  # will be used for naming the runs based on each run's hyper-parameters\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        train_loss, train_correct = 0, 0  # will be used to track the running loss and correct\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        network.train()  # set model to train mode\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)  # load the batch to the available device\n",
    "            preds = network(images)  # forward pass\n",
    "            loss = criterion(preds, labels)  # calculate loss\n",
    "            optimizer.zero_grad()  # clear accumulated gradients from the previous pass\n",
    "            loss.backward()  # backward pass\n",
    "            optimizer.step()  # perform a single optimization step\n",
    "\n",
    "            train_loss += loss.item() * run.batch_size  # update the running loss\n",
    "            train_correct += get_num_correct(preds, labels)  # update the running num correct\n",
    "\n",
    "        tb.add_scalar('Train Loss', train_loss, epoch)\n",
    "        tb.add_scalar('Train Accuracy', train_correct / len(train_set), epoch)\n",
    "        # add train loss and train accuracy for the current epoch to tensorboard\n",
    "        \n",
    "        network.eval()  # set the model to evaluation mode\n",
    "        with torch.no_grad():  # turn off grad tracking, as we don't need gradients for test\n",
    "            test_loss, test_correct = 0, 0  # will be used to track the running loss and correct\n",
    "            ##################\n",
    "            # test the model #\n",
    "            ##################\n",
    "            for batch in test_loader:\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)  # load the batch to the available device\n",
    "                preds = network(images)  # forward pass\n",
    "                loss = criterion(preds, labels)  # calculate the loss\n",
    "\n",
    "                test_loss += loss.item() * 1000  # update the running loss\n",
    "                test_correct += get_num_correct(preds, labels)  # update the running num correct\n",
    "\n",
    "            tb.add_scalar('Test Loss', test_loss, epoch)\n",
    "            tb.add_scalar('Test Accuracy', test_correct / len(test_set), epoch)\n",
    "            # add train loss and train accuracy for the current epoch to tensorboard\n",
    "\n",
    "        # iterate the parameters' weights and it's grads and plot their historgrams to tensorboard\n",
    "        # (will be helpful for checking if the model is having the vanishing gradient problem)\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "    # save the model\n",
    "    torch.save(network.state_dict(), f'./models/model-{run}.ckpt')\n"
   ]
  },
  {
   "source": [
    "__Note:__ this project uses Tensorboard as an evaluation utility for plotting running losses, accuracies, histograms etc. So if you are wondering why there are no outputs while the network is training, use Tensorboard (_open terminal, change path to project's repo and run this command `tensorboard --logdir=runs`_)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}